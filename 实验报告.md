# 神经网络简明教程-实践空间站 **实验报告**

## 1  线性回归模型  

> 给定含有1000条记录的数据集`mlm.csv`，其中每条记录均包含两个自变量`x`,`y`和一个因变量`z`，它们之间存在较为明显的线性关系。

**任务：请对数据进行三维可视化分析，并训练出良好的线性回归模型。**  

### **1.可视化结果**  

![可视化结果.png](https://i.loli.net/2021/01/04/hZ59Ewjmc1odMvT.png)

### **2.代码&注释**

读取文件，写成（1000,3）的list （除去文件开头的x y z）  

```python
import numpy as np  
from itertools import islice  
fi = open("Dataset/mlm.csv","r")  
ls = []  
for row in islice(fi, 1, None): 
    e = list(map(float,row.strip("\n").split(",")))  
    ls.append(e)  

#print(ls)
```

用list创建用来输入的x矩阵 和用于检查的y矩阵  

```python
x = np.array(ls).T
x = np.delete(x,2,0)

y = np.array(ls).T
y = np.delete(y,0,0)
y = np.delete(y,0,0)

#print(x)
#print(y.shape)
```  

按要求绘制可视化图像

```python

X = np.delete(x,0,0)
Y = np.delete(x,1,0)
Z = y

ax = plt.subplot(111,projection='3d') 
ax.scatter(X, Y, Z ,c="b")
plt.show()
```  

使用线性回归模型(a = np.dot(w.T,x) + b)  

随机初始化参数

```python
w = np.random.randn(2,1)
b = np.random.randn(1,1)

#print(w)
#print(b)
```  

计算估计值矩阵

```python
z = np.dot(w.T,x) + b
```

计算出参数梯度  

[(z-y)^2]/2作为损失函数  

```python
dz = z-y
dw = np.dot(x,dz.T)/ 10000000
db = np.sum( dz , axis=1 ,keepdims=True ) / 10000000
```

梯度下降  

```python
w -= dw
b -= db
```  

完整的做一次  

```python
z = np.dot(w.T,x) + b

dz = z-y
dw = np.dot(x,dz.T)/ 100000000
db = np.sum( dz , axis=1 ,keepdims=True ) / 100000000

w -= dw
b -= db
```

循环做100,000次

计算出百分误差

```python
for i in range(100000):
    z = np.dot(w.T,x) + b

    dz = z-y
    
    dw = np.dot(x,dz.T) / 10000000
    db = np.sum( dz , axis=1 ,keepdims=True ) / 1000

    w -= dw
    b -= db
ds = np.sum( abs(dz) , axis=1 ,keepdims=True )
s = np.sum( y , axis=1 ,keepdims=True )
print(100*ds/s)
```

带入3个测试点看一看误差  

```python
#[[64.32, 6.21, 236.5220491]
#[28.3, 22.62, 30.98357864]
#[19.69, 46.77, -89.8541616]

e = np.mat([[64.32], [6.21]])
print(np.dot(w.T,e) + b - 236.5220491)

e = np.mat([[28.3], [22.62]])
print(np.dot(w.T,e) + b - 30.98357864)

e = np.mat([[19.69], [46.77]])
print(np.dot(w.T,e) + b - -89.8541616)
```

### **3.备注**

linear regression 完整代码请看[此链接](https://github.com/Dar-Xs/Microsoft-ai-edu/blob/main/linear%20regression.ipynb)（代码语言：Jupyter Notebook (Python)）  

## 2  非线性多分类器

> 鸢尾花数据集`iris.csv`含有150条记录，每条记录包含萼片长度`sepal length`、萼片宽度`sepal width`、花瓣长度`petal length`和花瓣宽度`petal width`四个数值型特征，以及它的所属类别`class`（可能为`Iris-setosa`,`Iris-versicolor`,`Iris-virginica`三者之一）。  

**任务：请利用该数据集训练出一个良好的非线性分类器。**  
  
### **1.模型图示**  

![QQ图片20210109225700.jpg](https://i.loli.net/2021/01/09/N91OuTKyX7qw4He.jpg)

### **2.代码&注释**  

读取文件，写成（150,6）的list （除去文件开头的"花名"和"分类数据"）  

```python
import numpy as np
from itertools import islice

fi = open("Dataset/iris.csv","r")
ls = []
for row in islice(fi, 1, None):
    e = list(map(float,row.strip("\n").split(",")))
    ls.append(e)
    
print(ls)
```  

用list创建用来输入的x矩阵 和用于检查的y矩阵  

```python
x = np.array(ls).T
x = np.delete(x,4,0)
x = np.delete(x,4,0)
x = np.delete(x,4,0)

y = np.array(ls).T
y = np.delete(y,0,0)
y = np.delete(y,0,0)
y = np.delete(y,0,0)
y = np.delete(y,0,0)

#print(x)
#print(y)
```  

使用非线性三分类模型(a = np.dot(w.T,x) + b)  

随机初始化参数

```python
w1 = np.random.randn(4,16)/10
b1 = np.random.randn(16,1)/10

w2 = np.random.randn(16,8)/10
b2 = np.random.randn(8,1)/10

w3 = np.random.randn(8,3)/10
b3 = np.random.randn(3,1)/10

#print(w1)
#print(b1)
```

正向传播，计算估计值矩阵

```python
z1 = np.dot(w1.T,x) + b1
a1 = np.maximum(z1,0.01*z1)

z2 = np.dot(w2.T,z1) + b2
a2 = np.maximum(z2,0.01*z2)

z3 = np.dot(w3.T,z2) + b3
a30 = np.exp(z3)
a3 = a30/np.sum(a30, axis=0 ,keepdims=True )

#print(a3)
```

交叉熵作为损失函数

```L = -y*np.log(a3)-(1-y)*np.log(1-a3)
#print(L)
```

计算出参数梯度

```python
dz3 = a3 - y
dw3 = np.dot(a2,dz3.T)/150
db3 = np.sum( dz3 , axis=1 ,keepdims=True )/150

da2 = np.dot(w3,dz3)
dg2 = z2

dg2[dg2>= 0] = 1
dg2[dg2<0] = 0.01

dz2 = da2 * dg2

dw2 = np.dot(a1,dz2.T)/150
db2 = np.sum( dz2 , axis=1 ,keepdims=True )/150

da1 = np.dot(w2,dz2)
dg1 = z1

dg1[dg1>= 0] = 1
dg1[dg1<0] = 0.01

dz1 = da1 * dg1

dw1 = np.dot(x,dz1.T)/150
db1 = np.sum( dz1 , axis=1 ,keepdims=True )/150

print(dg1.shape)
```  

梯度下降

```python
w1 -= dw1/100
b1 -= db1/100

w2 -= dw2/100
b2 -= db2/100

w3 -= dw3/100
b3 -= db3/100
```

循环做50,000次

计算出百分误差

```python
for i in range(50000):
    z1 = np.dot(w1.T,x) + b1
    a1 = np.maximum(a1,0.01*a1)

    z2 = np.dot(w2.T,z1) + b2
    a2 = np.maximum(z2,0.01*a2)

    z3 = np.dot(w3.T,z2) + b3
    a30 = np.exp(z3)
    a3 = a30/np.sum(a30, axis=0 ,keepdims=True )
    
    #
    #
    #
    
    dz3 = a3 - y
    dw3 = np.dot(a2,dz3.T)/150
    db3 = np.sum( dz3 , axis=1 ,keepdims=True )/150

    da2 = np.dot(w3,dz3)
    dg2 = z2

    dg2[dg2>= 0] = 1
    dg2[dg2<0] = 0.01

    dz2 = da2 * dg2

    dw2 = np.dot(a1,dz2.T)/150
    db2 = np.sum( dz2 , axis=1 ,keepdims=True )/150

    da1 = np.dot(w2,dz2)
    dg1 = z1

    dg1[dg1>= 0] = 1
    dg1[dg1<0] = 0.01

    dz1 = da1 * dg1

    dw1 = np.dot(x,dz1.T)/150
    db1 = np.sum( dz1 , axis=1 ,keepdims=True )/150
    
    #
    #
    #
    
    w1 -= dw1/100
    b1 -= db1/100

    w2 -= dw2/200
    b2 -= db2/200

    w3 -= dw3/500
    b3 -= db3/500
    
ds = np.sum( abs(dz3) , axis=1 ,keepdims=True )
s = np.sum( y , axis=1 ,keepdims=True )
print(100*ds/s)
```

带入3个测试点看一看误差

```python
xt = np.mat([[5.9], [3.2], [4.8], [1.8]])
'''
[[5.1], [3.5], [1.4], [0.2], 1.0, 0.0, 0.0]->Iris-setosa
[[5.9], [3.2], [4.8], [1.8], 0.0, 1.0, 0.0]->Iris-versicolor
[[5.9], [3.0], [5.1], [1.8], 0.0, 0.0, 1.0]->Iris-virginica
'''

z1 = np.dot(w1.T,xt) + b1
a1 = np.maximum(a1,0.01*a1)

z2 = np.dot(w2.T,z1) + b2
a2 = np.maximum(z2,0.01*a2)

z3 = np.dot(w3.T,z2) + b3
a30 = np.exp(z3)
a3 = a30/np.sum(a30, axis=0 )

'''
ans = np.max(a3)
if( ans == a3[0] ):
    print("Iris-setosa\t"+ str(int(ans*100)) + "%")
elif( ans == a3[1] ):
    print("Iris-versicolor\t"+ str(int(ans*100)) + "%")
elif( ans == a3[2] ):
    print("Iris-virginica\t"+ str(int(ans*100)) + "%")
'''
print("Iris-setosa    \t"+ str(int(a3[0]*100)) + "%")
print("Iris-versicolor\t"+ str(int(a3[1]*100)) + "%")
print("Iris-virginica \t"+ str(int(a3[2]*100)) + "%")
```  

### **3.备注**  

在训练非线性三分类的时候，"Iris-versicolor" 和 "Iris-virginica" 两种花分类效果较差。  
究其根本还是这两种花在提供的4个参数上比较相近，差别细微，因而难以分类。

Nonlinear triple classification 完整代码请看[此链接](https://github.com/Dar-Xs/Microsoft-ai-edu/blob/main/Nonlinear%20triple%20classification.ipynb)（代码语言：Jupyter Notebook (Python)）
  
- - -

## **备注**

任务一的数据集由笔者自行模拟随机生成，任务二的Iris数据集来源于UCI Machine Learning Repository。  
